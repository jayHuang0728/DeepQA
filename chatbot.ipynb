{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is from https://github.com/escuccim/DeepQA which was forked from https://github.com/Conchylicultor/DeepQA. This notebook contains the ChatBot class and imports functions from other .py files. The original code has been edited and made to work in a notebook rather than the command line. \n",
    "\n",
    "Many of the parameters have been changed to allow this to be trained on a laptop GPU in a reasonable amount of time:\n",
    " * The embedding size was decreased from 100 to 56\n",
    " * The max output length was set to 8\n",
    " * The filter vocab parameters have also been changed.\n",
    " \n",
    "An attention mechanism was also added to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eric\\anaconda2\\envs\\hse_dl\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import configparser  # Saving the models parameters\n",
    "import datetime  # Chronometer\n",
    "import os  # Files management\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "from chatbot.textdata import TextData\n",
    "from chatbot.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we aren't running this on the command line create an args object with default values\n",
    "class Args():\n",
    "    def __init__(self, args=None):\n",
    "        self.test = None\n",
    "        self.createDataset = False\n",
    "        self.playDataset = False\n",
    "        self.reset = False\n",
    "        self.verbose = True\n",
    "        self.debug = False\n",
    "        self.keepAll = False\n",
    "        self.modelTag = None\n",
    "        self.rootDir = None\n",
    "        self.watsonMode = False\n",
    "        self.autoEncode = False\n",
    "        self.device = \"gpu\"\n",
    "        self.seed = 0\n",
    "        \n",
    "        # dataset options\n",
    "        self.corpus = \"opensubs\"\n",
    "        self.datasetTag = \"\"\n",
    "        self.ratioDataset = 1.0\n",
    "        self.maxLength = 8\n",
    "        self.filterVocab = 20\n",
    "        self.skipLines = False\n",
    "        self.vocabularySize = 50000\n",
    "        \n",
    "        # network options\n",
    "        self.hiddenSize = 512\n",
    "        self.numLayers = 2\n",
    "        self.softmaxSamples = 0\n",
    "        self.initEmbeddings = False\n",
    "        self.embeddingSize = 56\n",
    "        self.embeddingSource = \"GoogleNews-vectors-negative300.bin\"\n",
    "        \n",
    "        # training options\n",
    "        self.numEpochs = 2\n",
    "        self.saveEvery = 2000\n",
    "        self.batchSize = 196\n",
    "        self.learningRate = 0.002\n",
    "        self.dropout = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 Conchylicultor. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Main script. See README.md for more information\n",
    "\n",
    "Use python 3\n",
    "\"\"\"\n",
    "\n",
    "import configparser  # Saving the models parameters\n",
    "import datetime  # Chronometer\n",
    "import os  # Files management\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "from chatbot.textdata import TextData\n",
    "from chatbot.model import Model\n",
    "\n",
    "\n",
    "class Chatbot:\n",
    "    \"\"\"\n",
    "    Main class which launch the training or testing mode\n",
    "    \"\"\"\n",
    "\n",
    "    class TestMode:\n",
    "        \"\"\" Simple structure representing the different testing modes\n",
    "        \"\"\"\n",
    "        ALL = 'all'\n",
    "        INTERACTIVE = 'interactive'  # The user can write his own questions\n",
    "        DAEMON = 'daemon'  # The chatbot runs on background and can regularly be called to predict something\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Model/dataset parameters\n",
    "        self.args = None\n",
    "\n",
    "        # Task specific object\n",
    "        self.textData = None  # Dataset\n",
    "        self.model = None  # Sequence to sequence model\n",
    "\n",
    "        # Tensorflow utilities for convenience saving/logging\n",
    "        self.writer = None\n",
    "        self.saver = None\n",
    "        self.modelDir = ''  # Where the model is saved\n",
    "        self.globStep = 0  # Represent the number of iteration for the current model\n",
    "\n",
    "        # TensorFlow main session (we keep track for the daemon)\n",
    "        self.sess = None\n",
    "\n",
    "        # Filename and directories constants\n",
    "        self.MODEL_DIR_BASE = 'save2' + os.sep + 'model'\n",
    "        self.MODEL_NAME_BASE = 'model'\n",
    "        self.MODEL_EXT = '.ckpt'\n",
    "        self.CONFIG_FILENAME = 'params.ini'\n",
    "        self.CONFIG_VERSION = '0.5'\n",
    "        self.TEST_IN_NAME = 'data' + os.sep + 'test' + os.sep + 'samples.txt'\n",
    "        self.TEST_OUT_SUFFIX = '_predictions.txt'\n",
    "        self.SENTENCES_PREFIX = ['Q: ', 'A: ']\n",
    "\n",
    "    @staticmethod\n",
    "    def parseArgs(pargs):\n",
    "        args = Args(pargs)\n",
    "            \n",
    "        if pargs is not None and \"test\" in pargs:\n",
    "            args.test = pargs['test']\n",
    "        else:\n",
    "            args.test = None\n",
    "            \n",
    "        return args\n",
    "    \n",
    "    def start_session(self):\n",
    "         # Running session\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(\n",
    "            allow_soft_placement=True,  # Allows backup device for non GPU-available operations (when forcing GPU)\n",
    "            log_device_placement=False)  # Too verbose ?\n",
    "        )  # TODO: Replace all sess by self.sess (not necessary a good idea) ?\n",
    "\n",
    "        if self.args.debug:\n",
    "            self.sess = tf_debug.LocalCLIDebugWrapperSession(self.sess)\n",
    "            self.sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
    "\n",
    "        print('Initialize variables...')\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Reload the model eventually (if it exist.), on testing mode, the models are not loaded here (but in predictTestset)\n",
    "        if self.args.test != Chatbot.TestMode.ALL:\n",
    "            self.managePreviousModel(self.sess)\n",
    "\n",
    "        # Initialize embeddings with pre-trained word2vec vectors\n",
    "        if self.args.initEmbeddings:\n",
    "            self.loadEmbedding(self.sess)\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.loadModelParams()  # Update the self.modelDir and self.globStep, for now, not used when loading Model (but need to be called before _getSummaryName)\n",
    "\n",
    "        self.textData = TextData(self.args)\n",
    "        # TODO: Add a mode where we can force the input of the decoder // Try to visualize the predictions for\n",
    "        # each word of the vocabulary / decoder input\n",
    "        # TODO: For now, the model are trained for a specific dataset (because of the maxLength which define the\n",
    "        # vocabulary). Add a compatibility mode which allow to launch a model trained on a different vocabulary (\n",
    "        # remap the word2id/id2word variables).\n",
    "        if self.args.createDataset:\n",
    "            print('Dataset created! Thanks for using this program')\n",
    "            return  # No need to go further\n",
    "\n",
    "        # Prepare the model\n",
    "        with tf.device(self.getDevice()):\n",
    "            self.model = Model(self.args, self.textData)\n",
    "    \n",
    "    def main(self, pargs=None):\n",
    "        \"\"\"\n",
    "        Launch the training and/or the interactive mode\n",
    "        \"\"\"\n",
    "        print('Welcome to DeepQA v0.1 !')\n",
    "        print()\n",
    "        print('TensorFlow detected: v{}'.format(tf.__version__))\n",
    "\n",
    "        # General initialisation\n",
    "\n",
    "        self.args = self.parseArgs(pargs)\n",
    "\n",
    "        if not self.args.rootDir:\n",
    "            self.args.rootDir = os.getcwd()  # Use the current working directory\n",
    "\n",
    "        #tf.logging.set_verbosity(tf.logging.INFO) # DEBUG, INFO, WARN (default), ERROR, or FATAL\n",
    "\n",
    "        self.load_model()\n",
    "\n",
    "        # Saver/summaries\n",
    "        self.writer = tf.summary.FileWriter(self._getSummaryName())\n",
    "        self.saver = tf.train.Saver(max_to_keep=200)\n",
    "\n",
    "        # TODO: Fixed seed (WARNING: If dataset shuffling, make sure to do that after saving the\n",
    "        # dataset, otherwise, all which cames after the shuffling won't be replicable when\n",
    "        # reloading the dataset). How to restore the seed after loading ??\n",
    "        # Also fix seed for random.shuffle (does it works globally for all files ?)\n",
    "\n",
    "        self.start_session()\n",
    "\n",
    "        if self.args.test:\n",
    "            if self.args.test == Chatbot.TestMode.INTERACTIVE:\n",
    "                self.mainTestInteractive(self.sess)\n",
    "            elif self.args.test == Chatbot.TestMode.ALL:\n",
    "                print('Start predicting...')\n",
    "                self.predictTestset(self.sess)\n",
    "                print('All predictions done')\n",
    "            elif self.args.test == Chatbot.TestMode.DAEMON:\n",
    "                print('Daemon mode, running in background...')\n",
    "            else:\n",
    "                raise RuntimeError('Unknown test mode: {}'.format(self.args.test))  # Should never happen\n",
    "        else:\n",
    "            self.mainTrain(self.sess)\n",
    "\n",
    "        if self.args.test != Chatbot.TestMode.DAEMON:\n",
    "            self.sess.close()\n",
    "            print(\"The End! Thanks for using this program\")\n",
    "\n",
    "    def mainTrain(self, sess):\n",
    "        \"\"\" Training loop\n",
    "        Args:\n",
    "            sess: The current running session\n",
    "        \"\"\"\n",
    "\n",
    "        # Specific training dependent loading\n",
    "        self.textData.makeLighter(self.args.ratioDataset)  # Limit the number of training samples\n",
    "\n",
    "        mergedSummaries = tf.summary.merge_all()  # Define the summary operator (Warning: Won't appear on the tensorboard graph)\n",
    "        if self.globStep == 0:  # Not restoring from previous run\n",
    "            self.writer.add_graph(sess.graph)  # First time only\n",
    "\n",
    "        # If restoring a model, restore the progression bar ? and current batch ?\n",
    "        print('Start training (press Ctrl+C to save and exit)...')\n",
    "\n",
    "        try:  # If the user exit while training, we still try to save the model\n",
    "            for e in range(self.args.numEpochs):\n",
    "\n",
    "                print()\n",
    "                print(\"----- Epoch {}/{} ; (lr={}) -----\".format(e+1, self.args.numEpochs, self.args.learningRate))\n",
    "\n",
    "                batches = self.textData.getBatches()\n",
    "\n",
    "                # TODO: Also update learning parameters eventually\n",
    "\n",
    "                tic = datetime.datetime.now()\n",
    "                for nextBatch in tqdm(batches, desc=\"Training\"):\n",
    "                    # Training pass\n",
    "                    ops, feedDict = self.model.step(nextBatch)\n",
    "                    assert len(ops) == 2  # training, loss\n",
    "                    _, loss, summary = sess.run(ops + (mergedSummaries,), feedDict)\n",
    "                    self.writer.add_summary(summary, self.globStep)\n",
    "                    self.globStep += 1\n",
    "\n",
    "                    # Output training status\n",
    "                    if self.globStep % 100 == 0:\n",
    "                        perplexity = math.exp(float(loss)) if loss < 300 else float(\"inf\")\n",
    "                        tqdm.write(\"----- Step %d -- Loss %.2f -- Perplexity %.2f\" % (self.globStep, loss, perplexity))\n",
    "\n",
    "                    # Checkpoint\n",
    "                    if self.globStep % self.args.saveEvery == 0:\n",
    "                        self._saveSession(sess)\n",
    "\n",
    "                toc = datetime.datetime.now()\n",
    "\n",
    "                print(\"Epoch finished in {}\".format(toc-tic))  # Warning: Will overflow if an epoch takes more than 24 hours, and the output isn't really nicer\n",
    "        except (KeyboardInterrupt, SystemExit):  # If the user press Ctrl+C while testing progress\n",
    "            print('Interruption detected, exiting the program...')\n",
    "\n",
    "        self._saveSession(sess)  # Ultimate saving before complete exit\n",
    "\n",
    "    def predictTestset(self, sess):\n",
    "        \"\"\" Try predicting the sentences from the samples.txt file.\n",
    "        The sentences are saved on the modelDir under the same name\n",
    "        Args:\n",
    "            sess: The current running session\n",
    "        \"\"\"\n",
    "\n",
    "        # Loading the file to predict\n",
    "        with open(os.path.join(self.args.rootDir, self.TEST_IN_NAME), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        modelList = self._getModelList()\n",
    "        if not modelList:\n",
    "            print('Warning: No model found in \\'{}\\'. Please train a model before trying to predict'.format(self.modelDir))\n",
    "            return\n",
    "\n",
    "        # Predicting for each model present in modelDir\n",
    "        for modelName in sorted(modelList):  # TODO: Natural sorting\n",
    "            print('Restoring previous model from {}'.format(modelName))\n",
    "            self.saver.restore(sess, modelName)\n",
    "            print('Testing...')\n",
    "\n",
    "            saveName = modelName[:-len(self.MODEL_EXT)] + self.TEST_OUT_SUFFIX  # We remove the model extension and add the prediction suffix\n",
    "            with open(saveName, 'w') as f:\n",
    "                nbIgnored = 0\n",
    "                for line in tqdm(lines, desc='Sentences'):\n",
    "                    question = line[:-1]  # Remove the endl character\n",
    "\n",
    "                    answer = self.singlePredict(question)\n",
    "                    if not answer:\n",
    "                        nbIgnored += 1\n",
    "                        continue  # Back to the beginning, try again\n",
    "\n",
    "                    predString = '{x[0]}{0}\\n{x[1]}{1}\\n\\n'.format(question, self.textData.sequence2str(answer, clean=True), x=self.SENTENCES_PREFIX)\n",
    "                    if self.args.verbose:\n",
    "                        tqdm.write(predString)\n",
    "                    f.write(predString)\n",
    "                print('Prediction finished, {}/{} sentences ignored (too long)'.format(nbIgnored, len(lines)))\n",
    "\n",
    "    def mainTestInteractive(self, sess):\n",
    "        \"\"\" Try predicting the sentences that the user will enter in the console\n",
    "        Args:\n",
    "            sess: The current running session\n",
    "        \"\"\"\n",
    "        # TODO: If verbose mode, also show similar sentences from the training set with the same words (include in mainTest also)\n",
    "        # TODO: Also show the top 10 most likely predictions for each predicted output (when verbose mode)\n",
    "        # TODO: Log the questions asked for latter re-use (merge with test/samples.txt)\n",
    "\n",
    "        print('Testing: Launch interactive mode:')\n",
    "        print('')\n",
    "        print('Welcome to the interactive mode, here you can ask to Deep Q&A the sentence you want. Don\\'t have high '\n",
    "              'expectation. Type \\'exit\\' or just press ENTER to quit the program. Have fun.')\n",
    "\n",
    "        while True:\n",
    "            question = input(self.SENTENCES_PREFIX[0])\n",
    "            if question == '' or question == 'exit':\n",
    "                break\n",
    "\n",
    "            questionSeq = []  # Will be contain the question as seen by the encoder\n",
    "            answer = self.singlePredict(question, questionSeq)\n",
    "            if not answer:\n",
    "                print('Warning: sentence too long, sorry. Maybe try a simpler sentence.')\n",
    "                continue  # Back to the beginning, try again\n",
    "\n",
    "            print('{}{}'.format(self.SENTENCES_PREFIX[1], self.textData.sequence2str(answer, clean=True)))\n",
    "\n",
    "            if self.args.verbose:\n",
    "                print(self.textData.batchSeq2str(questionSeq, clean=True, reverse=True))\n",
    "                print(self.textData.sequence2str(answer))\n",
    "\n",
    "            print()\n",
    "    \n",
    "    def get_response(self, question):\n",
    "        return self.daemonPredict(question)\n",
    "    \n",
    "    def singlePredict(self, question, questionSeq=None):\n",
    "        \"\"\" Predict the sentence\n",
    "        Args:\n",
    "            question (str): the raw input sentence\n",
    "            questionSeq (List<int>): output argument. If given will contain the input batch sequence\n",
    "        Return:\n",
    "            list <int>: the word ids corresponding to the answer\n",
    "        \"\"\"\n",
    "        # Create the input batch\n",
    "        batch = self.textData.sentence2enco(question)\n",
    "        if not batch:\n",
    "            return None\n",
    "        if questionSeq is not None:  # If the caller want to have the real input\n",
    "            questionSeq.extend(batch.encoderSeqs)\n",
    "\n",
    "        # Run the model\n",
    "        ops, feedDict = self.model.step(batch)\n",
    "        output = self.sess.run(ops[0], feedDict)  # TODO: Summarize the output too (histogram, ...)\n",
    "        answer = self.textData.deco2sentence(output)\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def daemonPredict(self, sentence):\n",
    "        \"\"\" Return the answer to a given sentence (same as singlePredict() but with additional cleaning)\n",
    "        Args:\n",
    "            sentence (str): the raw input sentence\n",
    "        Return:\n",
    "            str: the human readable sentence\n",
    "        \"\"\"\n",
    "        return self.textData.sequence2str(\n",
    "            self.singlePredict(sentence),\n",
    "            clean=True\n",
    "        )\n",
    "\n",
    "    def daemonClose(self):\n",
    "        \"\"\" A utility function to close the daemon when finish\n",
    "        \"\"\"\n",
    "        print('Exiting the daemon mode...')\n",
    "        self.sess.close()\n",
    "        print('Daemon closed.')\n",
    "\n",
    "    def loadEmbedding(self, sess):\n",
    "        \"\"\" Initialize embeddings with pre-trained word2vec vectors\n",
    "        Will modify the embedding weights of the current loaded model\n",
    "        Uses the GoogleNews pre-trained values (path hardcoded)\n",
    "        \"\"\"\n",
    "\n",
    "        # Fetch embedding variables from model\n",
    "        with tf.variable_scope(\"embedding_rnn_seq2seq/rnn/embedding_wrapper\", reuse=True):\n",
    "            em_in = tf.get_variable(\"embedding\")\n",
    "        with tf.variable_scope(\"embedding_rnn_seq2seq/embedding_rnn_decoder\", reuse=True):\n",
    "            em_out = tf.get_variable(\"embedding\")\n",
    "\n",
    "        # Disable training for embeddings\n",
    "        variables = tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        variables.remove(em_in)\n",
    "        variables.remove(em_out)\n",
    "\n",
    "        # If restoring a model, we can leave here\n",
    "        if self.globStep != 0:\n",
    "            return\n",
    "\n",
    "        # New model, we load the pre-trained word2vec data and initialize embeddings\n",
    "        embeddings_path = os.path.join(self.args.rootDir, 'data', 'embeddings', self.args.embeddingSource)\n",
    "        embeddings_format = os.path.splitext(embeddings_path)[1][1:]\n",
    "        print(\"Loading pre-trained word embeddings from %s \" % embeddings_path)\n",
    "        with open(embeddings_path, \"rb\") as f:\n",
    "            header = f.readline()\n",
    "            vocab_size, vector_size = map(int, header.split())\n",
    "            binary_len = np.dtype('float32').itemsize * vector_size\n",
    "            initW = np.random.uniform(-0.25,0.25,(len(self.textData.word2id), vector_size))\n",
    "            for line in tqdm(range(vocab_size)):\n",
    "                word = []\n",
    "                while True:\n",
    "                    ch = f.read(1)\n",
    "                    if ch == b' ':\n",
    "                        word = b''.join(word).decode('utf-8')\n",
    "                        break\n",
    "                    if ch != b'\\n':\n",
    "                        word.append(ch)\n",
    "                if word in self.textData.word2id:\n",
    "                    if embeddings_format == 'bin':\n",
    "                        vector = np.fromstring(f.read(binary_len), dtype='float32')\n",
    "                    elif embeddings_format == 'vec':\n",
    "                        vector = np.fromstring(f.readline(), sep=' ', dtype='float32')\n",
    "                    else:\n",
    "                        raise Exception(\"Unkown format for embeddings: %s \" % embeddings_format)\n",
    "                    initW[self.textData.word2id[word]] = vector\n",
    "                else:\n",
    "                    if embeddings_format == 'bin':\n",
    "                        f.read(binary_len)\n",
    "                    elif embeddings_format == 'vec':\n",
    "                        f.readline()\n",
    "                    else:\n",
    "                        raise Exception(\"Unkown format for embeddings: %s \" % embeddings_format)\n",
    "\n",
    "        # PCA Decomposition to reduce word2vec dimensionality\n",
    "        if self.args.embeddingSize < vector_size:\n",
    "            U, s, Vt = np.linalg.svd(initW, full_matrices=False)\n",
    "            S = np.zeros((vector_size, vector_size), dtype=complex)\n",
    "            S[:vector_size, :vector_size] = np.diag(s)\n",
    "            initW = np.dot(U[:, :self.args.embeddingSize], S[:self.args.embeddingSize, :self.args.embeddingSize])\n",
    "\n",
    "        # Initialize input and output embeddings\n",
    "        sess.run(em_in.assign(initW))\n",
    "        sess.run(em_out.assign(initW))\n",
    "\n",
    "\n",
    "    def managePreviousModel(self, sess):\n",
    "        \"\"\" Restore or reset the model, depending of the parameters\n",
    "        If the destination directory already contains some file, it will handle the conflict as following:\n",
    "         * If --reset is set, all present files will be removed (warning: no confirmation is asked) and the training\n",
    "         restart from scratch (globStep & cie reinitialized)\n",
    "         * Otherwise, it will depend of the directory content. If the directory contains:\n",
    "           * No model files (only summary logs): works as a reset (restart from scratch)\n",
    "           * Other model files, but modelName not found (surely keepAll option changed): raise error, the user should\n",
    "           decide by himself what to do\n",
    "           * The right model file (eventually some other): no problem, simply resume the training\n",
    "        In any case, the directory will exist as it has been created by the summary writer\n",
    "        Args:\n",
    "            sess: The current running session\n",
    "        \"\"\"\n",
    "\n",
    "        print('WARNING: ', end='')\n",
    "\n",
    "        modelName = self._getModelName()\n",
    "\n",
    "        if os.listdir(self.modelDir):\n",
    "            if self.args.reset:\n",
    "                print('Reset: Destroying previous model at {}'.format(self.modelDir))\n",
    "            # Analysing directory content\n",
    "            elif os.path.exists(modelName):  # Restore the model\n",
    "                print('Restoring previous model from {}'.format(modelName))\n",
    "                self.saver.restore(sess, modelName)  # Will crash when --reset is not activated and the model has not been saved yet\n",
    "            elif self._getModelList():\n",
    "                print('Conflict with previous models.')\n",
    "                raise RuntimeError('Some models are already present in \\'{}\\'. You should check them first (or re-try with the keepAll flag)'.format(self.modelDir))\n",
    "            else:  # No other model to conflict with (probably summary files)\n",
    "                print('No previous model found, but some files found at {}. Cleaning...'.format(self.modelDir))  # Warning: No confirmation asked\n",
    "                self.args.reset = True\n",
    "\n",
    "            if self.args.reset:\n",
    "                fileList = [os.path.join(self.modelDir, f) for f in os.listdir(self.modelDir)]\n",
    "                for f in fileList:\n",
    "                    print('Removing {}'.format(f))\n",
    "                    os.remove(f)\n",
    "\n",
    "        else:\n",
    "            print('No previous model found, starting from clean directory: {}'.format(self.modelDir))\n",
    "\n",
    "    def _saveSession(self, sess):\n",
    "        \"\"\" Save the model parameters and the variables\n",
    "        Args:\n",
    "            sess: the current session\n",
    "        \"\"\"\n",
    "        tqdm.write('Checkpoint reached: saving model (don\\'t stop the run)...')\n",
    "        self.saveModelParams()\n",
    "        model_name = self._getModelName()\n",
    "        with open(model_name, 'w') as f:  # HACK: Simulate the old model existance to avoid rewriting the file parser\n",
    "            f.write('This file is used internally by DeepQA to check the model existance. Please do not remove.\\n')\n",
    "        self.saver.save(sess, model_name)  # TODO: Put a limit size (ex: 3GB for the modelDir)\n",
    "        tqdm.write('Model saved.')\n",
    "\n",
    "    def _getModelList(self):\n",
    "        \"\"\" Return the list of the model files inside the model directory\n",
    "        \"\"\"\n",
    "        return [os.path.join(self.modelDir, f) for f in os.listdir(self.modelDir) if f.endswith(self.MODEL_EXT)]\n",
    "\n",
    "    def loadModelParams(self):\n",
    "        \"\"\" Load the some values associated with the current model, like the current globStep value\n",
    "        For now, this function does not need to be called before loading the model (no parameters restored). However,\n",
    "        the modelDir name will be initialized here so it is required to call this function before managePreviousModel(),\n",
    "        _getModelName() or _getSummaryName()\n",
    "        Warning: if you modify this function, make sure the changes mirror saveModelParams, also check if the parameters\n",
    "        should be reset in managePreviousModel\n",
    "        \"\"\"\n",
    "        # Compute the current model path\n",
    "        self.modelDir = os.path.join(self.args.rootDir, self.MODEL_DIR_BASE)\n",
    "        if self.args.modelTag:\n",
    "            self.modelDir += '-' + self.args.modelTag\n",
    "\n",
    "        # If there is a previous model, restore some parameters\n",
    "        configName = os.path.join(self.modelDir, self.CONFIG_FILENAME)\n",
    "        if not self.args.reset and not self.args.createDataset and os.path.exists(configName):\n",
    "            # Loading\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read(configName)\n",
    "\n",
    "            # Check the version\n",
    "            currentVersion = config['General'].get('version')\n",
    "            if currentVersion != self.CONFIG_VERSION:\n",
    "                raise UserWarning('Present configuration version {0} does not match {1}. You can try manual changes on \\'{2}\\''.format(currentVersion, self.CONFIG_VERSION, configName))\n",
    "\n",
    "            # Restoring the the parameters\n",
    "            self.globStep = config['General'].getint('globStep')\n",
    "            self.args.watsonMode = config['General'].getboolean('watsonMode')\n",
    "            self.args.autoEncode = config['General'].getboolean('autoEncode')\n",
    "            self.args.corpus = config['General'].get('corpus')\n",
    "\n",
    "            self.args.datasetTag = config['Dataset'].get('datasetTag')\n",
    "            self.args.maxLength = config['Dataset'].getint('maxLength')  # We need to restore the model length because of the textData associated and the vocabulary size (TODO: Compatibility mode between different maxLength)\n",
    "            self.args.filterVocab = config['Dataset'].getint('filterVocab')\n",
    "            self.args.skipLines = config['Dataset'].getboolean('skipLines')\n",
    "            self.args.vocabularySize = config['Dataset'].getint('vocabularySize')\n",
    "\n",
    "            self.args.hiddenSize = config['Network'].getint('hiddenSize')\n",
    "            self.args.numLayers = config['Network'].getint('numLayers')\n",
    "            self.args.softmaxSamples = config['Network'].getint('softmaxSamples')\n",
    "            self.args.initEmbeddings = config['Network'].getboolean('initEmbeddings')\n",
    "            self.args.embeddingSize = config['Network'].getint('embeddingSize')\n",
    "            self.args.embeddingSource = config['Network'].get('embeddingSource')\n",
    "\n",
    "            # No restoring for training params, batch size or other non model dependent parameters\n",
    "\n",
    "            # Show the restored params\n",
    "            print()\n",
    "            print('Warning: Restoring parameters:')\n",
    "            print('globStep: {}'.format(self.globStep))\n",
    "            print('watsonMode: {}'.format(self.args.watsonMode))\n",
    "            print('autoEncode: {}'.format(self.args.autoEncode))\n",
    "            print('corpus: {}'.format(self.args.corpus))\n",
    "            print('datasetTag: {}'.format(self.args.datasetTag))\n",
    "            print('maxLength: {}'.format(self.args.maxLength))\n",
    "            print('filterVocab: {}'.format(self.args.filterVocab))\n",
    "            print('skipLines: {}'.format(self.args.skipLines))\n",
    "            print('vocabularySize: {}'.format(self.args.vocabularySize))\n",
    "            print('hiddenSize: {}'.format(self.args.hiddenSize))\n",
    "            print('numLayers: {}'.format(self.args.numLayers))\n",
    "            print('softmaxSamples: {}'.format(self.args.softmaxSamples))\n",
    "            print('initEmbeddings: {}'.format(self.args.initEmbeddings))\n",
    "            print('embeddingSize: {}'.format(self.args.embeddingSize))\n",
    "            print('embeddingSource: {}'.format(self.args.embeddingSource))\n",
    "            print()\n",
    "\n",
    "        # For now, not arbitrary  independent maxLength between encoder and decoder\n",
    "        self.args.maxLengthEnco = self.args.maxLength\n",
    "        self.args.maxLengthDeco = self.args.maxLength + 2\n",
    "\n",
    "        if self.args.watsonMode:\n",
    "            self.SENTENCES_PREFIX.reverse()\n",
    "\n",
    "\n",
    "    def saveModelParams(self):\n",
    "        \"\"\" Save the params of the model, like the current globStep value\n",
    "        Warning: if you modify this function, make sure the changes mirror loadModelParams\n",
    "        \"\"\"\n",
    "        config = configparser.ConfigParser()\n",
    "        config['General'] = {}\n",
    "        config['General']['version']  = self.CONFIG_VERSION\n",
    "        config['General']['globStep']  = str(self.globStep)\n",
    "        config['General']['watsonMode'] = str(self.args.watsonMode)\n",
    "        config['General']['autoEncode'] = str(self.args.autoEncode)\n",
    "        config['General']['corpus'] = str(self.args.corpus)\n",
    "\n",
    "        config['Dataset'] = {}\n",
    "        config['Dataset']['datasetTag'] = str(self.args.datasetTag)\n",
    "        config['Dataset']['maxLength'] = str(self.args.maxLength)\n",
    "        config['Dataset']['filterVocab'] = str(self.args.filterVocab)\n",
    "        config['Dataset']['skipLines'] = str(self.args.skipLines)\n",
    "        config['Dataset']['vocabularySize'] = str(self.args.vocabularySize)\n",
    "\n",
    "        config['Network'] = {}\n",
    "        config['Network']['hiddenSize'] = str(self.args.hiddenSize)\n",
    "        config['Network']['numLayers'] = str(self.args.numLayers)\n",
    "        config['Network']['softmaxSamples'] = str(self.args.softmaxSamples)\n",
    "        config['Network']['initEmbeddings'] = str(self.args.initEmbeddings)\n",
    "        config['Network']['embeddingSize'] = str(self.args.embeddingSize)\n",
    "        config['Network']['embeddingSource'] = str(self.args.embeddingSource)\n",
    "\n",
    "        # Keep track of the learning params (but without restoring them)\n",
    "        config['Training (won\\'t be restored)'] = {}\n",
    "        config['Training (won\\'t be restored)']['learningRate'] = str(self.args.learningRate)\n",
    "        config['Training (won\\'t be restored)']['batchSize'] = str(self.args.batchSize)\n",
    "        config['Training (won\\'t be restored)']['dropout'] = str(self.args.dropout)\n",
    "\n",
    "        with open(os.path.join(self.modelDir, self.CONFIG_FILENAME), 'w') as configFile:\n",
    "            config.write(configFile)\n",
    "\n",
    "    def _getSummaryName(self):\n",
    "        \"\"\" Parse the argument to decide were to save the summary, at the same place that the model\n",
    "        The folder could already contain logs if we restore the training, those will be merged\n",
    "        Return:\n",
    "            str: The path and name of the summary\n",
    "        \"\"\"\n",
    "        return self.modelDir\n",
    "\n",
    "    def _getModelName(self):\n",
    "        \"\"\" Parse the argument to decide were to save/load the model\n",
    "        This function is called at each checkpoint and the first time the model is load. If keepAll option is set, the\n",
    "        globStep value will be included in the name.\n",
    "        Return:\n",
    "            str: The path and name were the model need to be saved\n",
    "        \"\"\"\n",
    "        modelName = os.path.join(self.modelDir, self.MODEL_NAME_BASE)\n",
    "        if self.args.keepAll:  # We do not erase the previously saved model by including the current step on the name\n",
    "            modelName += '-' + str(self.globStep)\n",
    "        return modelName + self.MODEL_EXT\n",
    "\n",
    "    def getDevice(self):\n",
    "        \"\"\" Parse the argument to decide on which device run the model\n",
    "        Return:\n",
    "            str: The name of the device on which run the program\n",
    "        \"\"\"\n",
    "        if self.args.device == 'cpu':\n",
    "            return '/cpu:0'\n",
    "        elif self.args.device == 'gpu':\n",
    "            return '/gpu:0'\n",
    "        elif self.args.device is None:  # No specified device (default)\n",
    "            return None\n",
    "        else:\n",
    "            print('Warning: Error in the device name: {}, use the default device'.format(self.args.device))\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to DeepQA v0.1 !\n",
      "\n",
      "TensorFlow detected: v1.8.0\n",
      "\n",
      "Warning: Restoring parameters:\n",
      "globStep: 13902\n",
      "watsonMode: False\n",
      "autoEncode: False\n",
      "corpus: opensubs\n",
      "datasetTag: \n",
      "maxLength: 8\n",
      "filterVocab: 20\n",
      "skipLines: False\n",
      "vocabularySize: 50000\n",
      "hiddenSize: 512\n",
      "numLayers: 2\n",
      "softmaxSamples: 0\n",
      "initEmbeddings: False\n",
      "embeddingSize: 56\n",
      "embeddingSource: GoogleNews-vectors-negative300.bin\n",
      "\n",
      "Loading dataset from C:\\Users\\eric\\Documents\\Courses\\Advanced Deep Learning\\NLP\\natural-language-processing\\honor\\DeepQA\\data\\samples\\dataset-opensubs-length8-filter20-vocabSize50000.pkl\n",
      "Loaded opensubs: 14370 words, 660858 QA\n",
      "Model creation...\n",
      "Initialize variables...\n",
      "WARNING: Restoring previous model from C:\\Users\\eric\\Documents\\Courses\\Advanced Deep Learning\\NLP\\natural-language-processing\\honor\\DeepQA\\save2\\model\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\eric\\Documents\\Courses\\Advanced Deep Learning\\NLP\\natural-language-processing\\honor\\DeepQA\\save2\\model\\model.ckpt\n",
      "Start training (press Ctrl+C to save and exit)...\n",
      "\n",
      "----- Epoch 1/2 ; (lr=0.002) -----\n",
      "Shuffling the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14000 -- Loss 2.99 -- Perplexity 19.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: saving model (don't stop the run)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14100 -- Loss 3.09 -- Perplexity 21.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14200 -- Loss 2.99 -- Perplexity 19.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14300 -- Loss 3.03 -- Perplexity 20.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14400 -- Loss 3.14 -- Perplexity 23.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14500 -- Loss 3.03 -- Perplexity 20.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14600 -- Loss 3.11 -- Perplexity 22.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14700 -- Loss 3.21 -- Perplexity 24.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14800 -- Loss 3.21 -- Perplexity 24.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 14900 -- Loss 3.06 -- Perplexity 21.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15000 -- Loss 3.01 -- Perplexity 20.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15100 -- Loss 3.01 -- Perplexity 20.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15200 -- Loss 3.10 -- Perplexity 22.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15300 -- Loss 3.07 -- Perplexity 21.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15400 -- Loss 3.15 -- Perplexity 23.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15500 -- Loss 3.13 -- Perplexity 22.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15600 -- Loss 3.09 -- Perplexity 21.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15700 -- Loss 3.10 -- Perplexity 22.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15800 -- Loss 3.22 -- Perplexity 25.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 15900 -- Loss 3.11 -- Perplexity 22.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16000 -- Loss 3.11 -- Perplexity 22.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: saving model (don't stop the run)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16100 -- Loss 2.96 -- Perplexity 19.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16200 -- Loss 3.00 -- Perplexity 20.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16300 -- Loss 2.96 -- Perplexity 19.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16400 -- Loss 3.10 -- Perplexity 22.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16500 -- Loss 3.15 -- Perplexity 23.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16600 -- Loss 3.06 -- Perplexity 21.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16700 -- Loss 3.08 -- Perplexity 21.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16800 -- Loss 3.04 -- Perplexity 20.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 16900 -- Loss 3.09 -- Perplexity 22.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17000 -- Loss 3.08 -- Perplexity 21.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17100 -- Loss 3.13 -- Perplexity 22.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17200 -- Loss 3.14 -- Perplexity 23.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 3372/3372 [17:18:15<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished in 17:18:15.689953\n",
      "\n",
      "----- Epoch 2/2 ; (lr=0.002) -----\n",
      "Shuffling the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17300 -- Loss 3.01 -- Perplexity 20.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17400 -- Loss 2.90 -- Perplexity 18.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17500 -- Loss 3.05 -- Perplexity 21.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17600 -- Loss 2.95 -- Perplexity 19.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17700 -- Loss 2.89 -- Perplexity 18.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17800 -- Loss 2.99 -- Perplexity 19.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 17900 -- Loss 2.87 -- Perplexity 17.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 18000 -- Loss 3.03 -- Perplexity 20.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: saving model (don't stop the run)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 18100 -- Loss 3.04 -- Perplexity 21.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 18200 -- Loss 2.89 -- Perplexity 18.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 18300 -- Loss 2.97 -- Perplexity 19.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Step 18400 -- Loss 2.92 -- Perplexity 18.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|                                                                                                       | 1224/3372 [1:23:29<3:17:35,  5.52s/it]"
     ]
    }
   ],
   "source": [
    "chatbot.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to DeepQA v0.1 !\n",
      "\n",
      "TensorFlow detected: v1.8.0\n",
      "\n",
      "Warning: Restoring parameters:\n",
      "globStep: 13902\n",
      "watsonMode: False\n",
      "autoEncode: False\n",
      "corpus: opensubs\n",
      "datasetTag: \n",
      "maxLength: 8\n",
      "filterVocab: 20\n",
      "skipLines: False\n",
      "vocabularySize: 50000\n",
      "hiddenSize: 512\n",
      "numLayers: 2\n",
      "softmaxSamples: 0\n",
      "initEmbeddings: False\n",
      "embeddingSize: 56\n",
      "embeddingSource: GoogleNews-vectors-negative300.bin\n",
      "\n",
      "Loading dataset from C:\\Users\\eric\\Documents\\Courses\\Advanced Deep Learning\\NLP\\natural-language-processing\\honor\\DeepQA\\data\\samples\\dataset-opensubs-length8-filter20-vocabSize50000.pkl\n",
      "Loaded opensubs: 14370 words, 660858 QA\n",
      "Model creation...\n",
      "Initialize variables...\n",
      "WARNING: Restoring previous model from C:\\Users\\eric\\Documents\\Courses\\Advanced Deep Learning\\NLP\\natural-language-processing\\honor\\DeepQA\\save2\\model\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\eric\\Documents\\Courses\\Advanced Deep Learning\\NLP\\natural-language-processing\\honor\\DeepQA\\save2\\model\\model.ckpt\n",
      "Daemon mode, running in background...\n"
     ]
    }
   ],
   "source": [
    "chatbot.main(pargs={\"test\": Chatbot.TestMode.DAEMON})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And i' m not\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.daemonPredict(\"What is your name?\")\n",
    "chatbot.daemonPredict(\"How are you?\")\n",
    "chatbot.daemonPredict(\"What is your hobby?\")\n",
    "chatbot.daemonPredict(\"How old are you ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
